# <p align="center">Climate Adaptation with Reinforcement Learning: Experiments with Flooding and Transportation in Copenhagen</p>

## Description

Supporting materials for the article "Climate Adaptation with Reinforcement Learning: Experiments with Flooding and Transportation in Copenhagen", accepted for presentation at Tackling Climate Change with Machine Learning workshop at NeurIPS 2024.

The manuscript can be found [here](https://arxiv.org/abs/2409.18574).


## Abstract
Due to climate change the frequency and intensity of extreme rainfall events, which contribute to urban flooding, are expected to increase in many places. These floods can damage transport infrastructure and disrupt mobility, highlighting the need for cities to adapt to escalating risks. Reinforcement learning (RL) serves as a powerful tool for uncovering optimal adaptation strategies, determining how and where to deploy adaptation measures effectively, even under significant uncertainty. In this study, we leverage RL to identify the most effective timing and locations for implementing measures, aiming to reduce both direct and indirect impacts of flooding. Our framework integrates climate change projections of future rainfall events and floods, models city-wide motorized trips, and quantifies direct and indirect impacts on infrastructure and mobility. Preliminary results suggest that our RL-based approach can significantly enhance decision-making by prioritizing interventions in specific urban areas and identifying the optimal periods for their implementation. 


## How to cite

If you use and find these materials useful, please cite as:

```
@article{costa2024climate,
  title={Climate Adaptation with Reinforcement Learning: Experiments with Flooding and Transportation in Copenhagen},
  author={Miguel Costa and Morten W. Petersen and Arthur Vandervoort and Martin Drews and Karyn Morrissey and Francisco C. Pereira},
  journal={arXiv preprint arXiv:2409.18574},
  year={2024}
}
```


























